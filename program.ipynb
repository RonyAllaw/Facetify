{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(path, detector=MTCNN(), required_size=(160,160), save_faces=True):\n",
    "  # load image from file\n",
    "  image = Image.open(path)\n",
    "\n",
    "  # convert to rgb\n",
    "  image = image.convert('RGB')\n",
    "\n",
    "  # covert to array\n",
    "  pixels = np.asarray(image)\n",
    "\n",
    "  #detect faces in the image\n",
    "  results = detector.detect_faces(pixels)\n",
    "\n",
    "  # extract the bounding box from the first face\n",
    "  x1, y1, width, height = results[0]['box']\n",
    "\n",
    "  # bug fix\n",
    "  x1, y1 = abs(x1), abs(y1)\n",
    "  x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "  # extract the face\n",
    "  face = pixels[y1:y2, x1:x2]\n",
    "\n",
    "  # resize pixels to the model size\n",
    "  image = Image.fromarray(face)\n",
    "  image = image.resize(required_size)\n",
    "\n",
    "  face_array = np.asarray(image)\n",
    "  return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save X and Y into a zip file and load it:\n",
    "# np.savez_compressed('FileName.npz', X's (faces as np array), Y's (labels))\n",
    "# we can load them using :\n",
    "# data = np.load(path of .npz)\n",
    "# X, Y = data['arr_0'], data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "  # scale pixel values\n",
    "  face_pixels = face_pixels.astype('float32')\n",
    "\n",
    "  # normalization\n",
    "  mean, std = face_pixels.mean(), face_pixels.std()\n",
    "  face_pixels = (face_pixels - mean) / std\n",
    "  \n",
    "  # transform face into one sample\n",
    "  samples = np.expand_dims(face_pixels, axis=0)\n",
    "\n",
    "  # make predictions to get embeddings\n",
    "  yhat = model.predict(samples)\n",
    "\n",
    "  return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the photos\n",
    "# data = np.load(path of .npz)\n",
    "# X, Y = data['arr_0'], data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the facenet model\n",
    "model = tf.keras.models.load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings of all pics\n",
    "# img_pixels = extract_face('man.jpg')\n",
    "# embeddings = get_embedding(model, img_pixels)\n",
    "# make the embeddings np array\n",
    "# save them using np.savez_compressed(name.npz, embeddings np array, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras model\n",
    "# model = tf.keras.models.load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_distance(faces_embeddings, labels, face_to_predict_embeddings):\n",
    "  # normalize input vector\n",
    "  in_encoder = Normalizer(norm='l2')\n",
    "  faces_embeddings = in_encoder.transform(faces_embeddings)\n",
    "  face_to_predict_embeddings = in_encoder.transform(face_to_predict_embeddings)\n",
    "\n",
    "  # use euclidean distance\n",
    "  # the distance gives how similar the faces are\n",
    "  face_distance = np.linalg.norm(faces_embeddings - face_to_predict_embeddings, axis=1)\n",
    "\n",
    "  name = 'Unknown'\n",
    "\n",
    "  # put threshold for the distance to know if the person is found or not\n",
    "  threshold = 0.7\n",
    "\n",
    "  # list of matching people\n",
    "  matching = []\n",
    "  for i in range(len(face_distance)):\n",
    "    if(face_distance[i] < threshold):\n",
    "      matching.append([face_distance[i], labels[i]])\n",
    "  \n",
    "  min_label = 'Unknown'\n",
    "  min_dist = 213124\n",
    "  for i in range(len(matching)):\n",
    "    if(matching[i][0] < min_dist):\n",
    "      min_dist = matching[i][0]\n",
    "      min_label = matching[i][1]\n",
    "    \n",
    "  return min_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = extract_face('michael-jordan.jpg')\n",
    "# img2 = extract_face('michael-jordan2.jpg')\n",
    "# X = [img1, img2]\n",
    "# Y = np.asarray(['michael-jordan', 'michael-jordan'])\n",
    "\n",
    "# for i in range(len(X)):\n",
    "#   X[i] = get_embedding(model, X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img3 = extract_face('michael-jordan3.jpg')\n",
    "# img3_emb = get_embedding(model, img3)\n",
    "\n",
    "# img4 = extract_face('man.jpg')\n",
    "# img4_emb = get_embedding(model, img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img5 = extract_face('michael-jordan-t.jpg')\n",
    "# img5_emb = get_embedding(model, img5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predict_using_distance(np.asarray(X), Y, img5_emb.reshape(1,-1)))"
   ]
  }
 ]
}